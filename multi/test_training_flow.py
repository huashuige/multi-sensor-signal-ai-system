#!/usr/bin/env python
"""
æµ‹è¯•ä»è®­ç»ƒé›†å¼€å§‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import django
import json

# è®¾ç½®Djangoç¯å¢ƒ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')
django.setup()

def test_training_flow():
    """æµ‹è¯•è®­ç»ƒæµç¨‹"""
    print("=" * 60)
    print("æµ‹è¯•ä»è®­ç»ƒé›†å¼€å§‹è®­ç»ƒçš„å®Œæ•´æµç¨‹")
    print("=" * 60)
    
    try:
        from polls.models import TrainingSet, MonitorTask
        
        # 1. æ£€æŸ¥è®­ç»ƒé›†
        print("\n1. æ£€æŸ¥è®­ç»ƒé›†...")
        training_sets = TrainingSet.objects.filter(is_deleted=False)
        print(f"æ‰¾åˆ° {training_sets.count()} ä¸ªè®­ç»ƒé›†")
        
        for ts in training_sets[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  - {ts.name} (ID: {ts.training_set_id})")
            print(f"    çŠ¶æ€: {ts.status}, æ¨¡å¼: {ts.training_mode}")
            print(f"    å­¦ä¹ å‚æ•°: {ts.learning_params}")
            print(f"    æ•°æ®æº: {ts.selected_data_sources}")
        
        # 2. æ£€æŸ¥ç›‘æ§ä»»åŠ¡
        print("\n2. æ£€æŸ¥ç›‘æ§ä»»åŠ¡...")
        tasks = MonitorTask.objects.all()
        print(f"æ‰¾åˆ° {tasks.count()} ä¸ªç›‘æ§ä»»åŠ¡")
        
        for task in tasks[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  - {task.task_name} (ID: {task.task_id})")
            print(f"    CSVæ–‡ä»¶: {task.csv_file_path}")
            print(f"    æ•°æ®ç‚¹æ•°: {task.total_data_points}")
            print(f"    å¯ç”¨é€šé“: {task.enabled_channels}")
        
        # 3. æµ‹è¯•æ•°æ®åŠ è½½å™¨
        print("\n3. æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
        from polls.sensor_data_loader import SensorDataLoader
        
        loader = SensorDataLoader()
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # 4. æµ‹è¯•LSTMæ¨¡å‹
        print("\n4. æµ‹è¯•LSTMæ¨¡å‹...")
        from polls.multi_channel_lstm import MultiChannelLSTM
        
        model = MultiChannelLSTM(
            num_channels=4,
            hidden_size=64,
            num_layers=2,
            horizon=12
        )
        print("âœ… LSTMæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # 5. æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹
        print("\n5. æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹...")
        if training_sets.exists():
            training_set = training_sets.first()
            print(f"é€‰æ‹©è®­ç»ƒé›†: {training_set.name}")
            
            # è·å–å­¦ä¹ å‚æ•°
            learning_params = training_set.learning_params
            if learning_params:
                print(f"å­¦ä¹ å‚æ•°: {learning_params}")
            else:
                print("âš ï¸  è®­ç»ƒé›†æ²¡æœ‰é…ç½®å­¦ä¹ å‚æ•°")
                learning_params = {
                    'window_size': 24,
                    'horizon': 12,
                    'hidden_size': 64,
                    'num_layers': 2,
                    'dropout': 0.1,
                    'batch_size': 32,
                    'epochs': 50,
                    'lr': 0.001,
                    'patience': 10
                }
                print(f"ä½¿ç”¨é»˜è®¤å‚æ•°: {learning_params}")
            
            # è·å–æ•°æ®æº
            selected_data_sources = training_set.selected_data_sources
            if selected_data_sources:
                print(f"æ•°æ®æº: {selected_data_sources}")
                
                # æå–ä»»åŠ¡IDå’Œé€šé“
                task_ids = []
                channels = []
                
                for data_source in selected_data_sources:
                    task_ids.append(data_source.get('task_id'))
                    channels.extend(data_source.get('channels', []))
                
                channels = list(set(channels))  # å»é‡
                
                print(f"ä»»åŠ¡ID: {task_ids}")
                print(f"é€šé“: {channels}")
                
                # æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                for task_id in task_ids:
                    try:
                        task = MonitorTask.objects.get(task_id=task_id)
                        csv_path = task.csv_file_path
                        if os.path.exists(csv_path):
                            print(f"âœ… CSVæ–‡ä»¶å­˜åœ¨: {csv_path}")
                        else:
                            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
                    except MonitorTask.DoesNotExist:
                        print(f"âŒ ä»»åŠ¡IDä¸å­˜åœ¨: {task_id}")
                
            else:
                print("âš ï¸  è®­ç»ƒé›†æ²¡æœ‰é€‰æ‹©æ•°æ®æº")
        
        print("\n" + "=" * 60)
        print("âœ… è®­ç»ƒæµç¨‹æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_api_endpoints():
    """æµ‹è¯•APIç«¯ç‚¹"""
    print("\næµ‹è¯•APIç«¯ç‚¹...")
    
    try:
        from polls import deep_learning_views
        
        # æµ‹è¯•è·å–è®­ç»ƒé›†ä¿¡æ¯
        print("âœ… deep_learning_views å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•å…¶ä»–å¯¼å…¥
        from polls.sensor_data_loader import train_multi_channel_model
        print("âœ… train_multi_channel_model å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ APIç«¯ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test1 = test_training_flow()
    test2 = test_api_endpoints()
    
    if test1 and test2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚") 
"""
æµ‹è¯•ä»è®­ç»ƒé›†å¼€å§‹è®­ç»ƒçš„å®Œæ•´æµç¨‹
"""

import os
import sys
import django
import json

# è®¾ç½®Djangoç¯å¢ƒ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')
django.setup()

def test_training_flow():
    """æµ‹è¯•è®­ç»ƒæµç¨‹"""
    print("=" * 60)
    print("æµ‹è¯•ä»è®­ç»ƒé›†å¼€å§‹è®­ç»ƒçš„å®Œæ•´æµç¨‹")
    print("=" * 60)
    
    try:
        from polls.models import TrainingSet, MonitorTask
        
        # 1. æ£€æŸ¥è®­ç»ƒé›†
        print("\n1. æ£€æŸ¥è®­ç»ƒé›†...")
        training_sets = TrainingSet.objects.filter(is_deleted=False)
        print(f"æ‰¾åˆ° {training_sets.count()} ä¸ªè®­ç»ƒé›†")
        
        for ts in training_sets[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  - {ts.name} (ID: {ts.training_set_id})")
            print(f"    çŠ¶æ€: {ts.status}, æ¨¡å¼: {ts.training_mode}")
            print(f"    å­¦ä¹ å‚æ•°: {ts.learning_params}")
            print(f"    æ•°æ®æº: {ts.selected_data_sources}")
        
        # 2. æ£€æŸ¥ç›‘æ§ä»»åŠ¡
        print("\n2. æ£€æŸ¥ç›‘æ§ä»»åŠ¡...")
        tasks = MonitorTask.objects.all()
        print(f"æ‰¾åˆ° {tasks.count()} ä¸ªç›‘æ§ä»»åŠ¡")
        
        for task in tasks[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            print(f"  - {task.task_name} (ID: {task.task_id})")
            print(f"    CSVæ–‡ä»¶: {task.csv_file_path}")
            print(f"    æ•°æ®ç‚¹æ•°: {task.total_data_points}")
            print(f"    å¯ç”¨é€šé“: {task.enabled_channels}")
        
        # 3. æµ‹è¯•æ•°æ®åŠ è½½å™¨
        print("\n3. æµ‹è¯•æ•°æ®åŠ è½½å™¨...")
        from polls.sensor_data_loader import SensorDataLoader
        
        loader = SensorDataLoader()
        print("âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # 4. æµ‹è¯•LSTMæ¨¡å‹
        print("\n4. æµ‹è¯•LSTMæ¨¡å‹...")
        from polls.multi_channel_lstm import MultiChannelLSTM
        
        model = MultiChannelLSTM(
            num_channels=4,
            hidden_size=64,
            num_layers=2,
            horizon=12
        )
        print("âœ… LSTMæ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # 5. æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹
        print("\n5. æ¨¡æ‹Ÿè®­ç»ƒæµç¨‹...")
        if training_sets.exists():
            training_set = training_sets.first()
            print(f"é€‰æ‹©è®­ç»ƒé›†: {training_set.name}")
            
            # è·å–å­¦ä¹ å‚æ•°
            learning_params = training_set.learning_params
            if learning_params:
                print(f"å­¦ä¹ å‚æ•°: {learning_params}")
            else:
                print("âš ï¸  è®­ç»ƒé›†æ²¡æœ‰é…ç½®å­¦ä¹ å‚æ•°")
                learning_params = {
                    'window_size': 24,
                    'horizon': 12,
                    'hidden_size': 64,
                    'num_layers': 2,
                    'dropout': 0.1,
                    'batch_size': 32,
                    'epochs': 50,
                    'lr': 0.001,
                    'patience': 10
                }
                print(f"ä½¿ç”¨é»˜è®¤å‚æ•°: {learning_params}")
            
            # è·å–æ•°æ®æº
            selected_data_sources = training_set.selected_data_sources
            if selected_data_sources:
                print(f"æ•°æ®æº: {selected_data_sources}")
                
                # æå–ä»»åŠ¡IDå’Œé€šé“
                task_ids = []
                channels = []
                
                for data_source in selected_data_sources:
                    task_ids.append(data_source.get('task_id'))
                    channels.extend(data_source.get('channels', []))
                
                channels = list(set(channels))  # å»é‡
                
                print(f"ä»»åŠ¡ID: {task_ids}")
                print(f"é€šé“: {channels}")
                
                # æ£€æŸ¥CSVæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                for task_id in task_ids:
                    try:
                        task = MonitorTask.objects.get(task_id=task_id)
                        csv_path = task.csv_file_path
                        if os.path.exists(csv_path):
                            print(f"âœ… CSVæ–‡ä»¶å­˜åœ¨: {csv_path}")
                        else:
                            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
                    except MonitorTask.DoesNotExist:
                        print(f"âŒ ä»»åŠ¡IDä¸å­˜åœ¨: {task_id}")
                
            else:
                print("âš ï¸  è®­ç»ƒé›†æ²¡æœ‰é€‰æ‹©æ•°æ®æº")
        
        print("\n" + "=" * 60)
        print("âœ… è®­ç»ƒæµç¨‹æµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_api_endpoints():
    """æµ‹è¯•APIç«¯ç‚¹"""
    print("\næµ‹è¯•APIç«¯ç‚¹...")
    
    try:
        from polls import deep_learning_views
        
        # æµ‹è¯•è·å–è®­ç»ƒé›†ä¿¡æ¯
        print("âœ… deep_learning_views å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•å…¶ä»–å¯¼å…¥
        from polls.sensor_data_loader import train_multi_channel_model
        print("âœ… train_multi_channel_model å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ APIç«¯ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    test1 = test_training_flow()
    test2 = test_api_endpoints()
    
    if test1 and test2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
    else:
        print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚") 
 
 